<h2 id="publications" style="margin: 2px 0px -15px;">Publications</h2>

<div class="publications">
<ol class="bibliography">

<li>
<div class="pub-row">
  <div class="col-sm-3 abbr" style="position: relative;padding-right: 15px;padding-left: 15px;">
    <img src="assets/paper_imgs/mavos.png" class="teaser img-fluid z-depth-1">
    <abbr class="badge">WACV</abbr>
  </div>
  <div class="col-sm-9" style="position: relative;width: 100%;padding-right: 15px;padding-left: 20px;">
    <div class="title">Efficient Video Object Segmentation via Modulated Cross-Attention Memory</div>
    <div class="author">Abdelrahman Shaker, <strong>Syed Talal Wasim</strong>, Martin Danelljan, Salman Khan, Ming-Hsuan Yang and Fahad Shahbaz Khan</div>
    <div class="periodical"><em>WACV, 2025</em></div>
    <div class="links">
      <a href="https://arxiv.org/abs/2403.17937" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">PAPER</a>
      <a href="https://github.com/Amshaker/MAVOS" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">CODE</a>
      <!-- <a href="#bibtex-citation-mavos" class="btn btn-sm z-depth-0 bibtex-btn" role="button" target="_blank" style="font-size:12px;">BIBTEX</a> -->
    </div>
    <div id="bibtex-citation-mavos" class="bibtex-citation" style="display: none;">
      @inproceedings{shaker2025mavos,
        title={Efficient Video Object Segmentation via Modulated Cross-Attention Memory},
        author={Abdelrahman Shaker and Syed Talal Wasim and Martin Danelljan and Salman Khan and Ming-Hsuan Yang and Fahad Shahbaz Khan},
        booktitle={WACV}
        year={2025}
      }
  </div>
  </div>
</div>
</li>

<br>

<li>
<div class="pub-row">
  <div class="col-sm-3 abbr" style="position: relative;padding-right: 15px;padding-left: 15px;">
    <img src="assets/paper_imgs/vpanda.jpg" class="teaser img-fluid z-depth-1">
    <abbr class="badge">Under Review</abbr>
  </div>
  <div class="col-sm-9" style="position: relative;width: 100%;padding-right: 15px;padding-left: 20px;">
    <div class="title">Video-Panda: Parameter-efficient Alignment for Encoder-free Video-Language Models</div>
    <div class="author">Jinhui Yi*, <strong>Syed Talal Wasim</strong>*, Yanan Luo*, Muzammal Naseer and Juergen Gall</div>
    <div class="periodical"><em>Under Review</em></div>
    <div class="links">
      <a href="https://talalwasim.github.io" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">PAPER</a>
      <a href="https://talalwasim.github.io" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">CODE</a>
    </div>
  </div>
</div>
</li>

<br>

<li>
<div class="pub-row">
  <div class="col-sm-3 abbr" style="position: relative;padding-right: 15px;padding-left: 15px;">
    <img src="assets/paper_imgs/sting.jpg" class="teaser img-fluid z-depth-1">
    <abbr class="badge">Under Review</abbr>
  </div>
  <div class="col-sm-9" style="position: relative;width: 100%;padding-right: 15px;padding-left: 20px;">
    <div class="title">STING-BEE: Towards Vision-Language Model for Real-World X-ray Baggage Security Inspection</div>
    <div class="author">Divya Velayudhan, Abdelfatah Ahmed, Mohamad Alansari, Neha Gour, Abderaouf Behouch, Taimur Hassan, <strong>Syed Talal Wasim</strong>, Nabil Maalej, Muzammal Naseer, Juergen Gall, Mohammed Bennamoun, Ernesto Damiani and Naoufel Werghi </div>
    <div class="periodical"><em>Under Review</em></div>
    <div class="links">
      <a href="https://talalwasim.github.io" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">PAPER</a>
      <a href="https://talalwasim.github.io" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">CODE</a>
    </div>
  </div>
</div>
</li>

<br>

<li>
<div class="pub-row">
  <div class="col-sm-3 abbr" style="position: relative;padding-right: 15px;padding-left: 15px;">
    <img src="assets/paper_imgs/groupmamba.png" class="teaser img-fluid z-depth-1">
    <abbr class="badge">Under Review</abbr>
  </div>
  <div class="col-sm-9" style="position: relative;width: 100%;padding-right: 15px;padding-left: 20px;">
    <div class="title">GroupMamba: Parameter-Efficient and Accurate Group Visual State Space Model</div>
    <div class="author">Abdelrahman Shaker, <strong>Syed Talal Wasim</strong>, Salman Khan, and Fahad Shahbaz Khan</div>
    <div class="periodical"><em>Under Review</em></div>
    <div class="links">
      <a href="https://arxiv.org/abs/2407.13772" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">PAPER</a>
      <a href="https://github.com/Amshaker/GroupMamba" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">CODE</a>
    </div>
  </div>
</div>
</li>

<br>

<li>
<div class="pub-row">
  <div class="col-sm-3 abbr" style="position: relative;padding-right: 15px;padding-left: 15px;">
    <img src="assets/paper_imgs/stablemamba.png" class="teaser img-fluid z-depth-1">
    <abbr class="badge">Under Review</abbr>
  </div>
  <div class="col-sm-9" style="position: relative;width: 100%;padding-right: 15px;padding-left: 20px;">
    <div class="title">Distillation-free Scaling of Large SSMs for Images and Videos</div>
    <div class="author">Hamid Suleman*, <strong>Syed Talal Wasim</strong>*, Muzammal Naseer and Juergen Gall</div>
    <div class="periodical"><em>Under Review</em></div>
    <div class="links">
      <a href="https://arxiv.org/abs/2409.11867" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">PAPER</a>
      <a href="https://talalwasim.github.io" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">CODE</a>
    </div>
  </div>
</div>
</li>

<br>

<li>
<div class="pub-row">
  <div class="col-sm-3 abbr" style="position: relative;padding-right: 15px;padding-left: 15px;">
    <img src="assets/paper_imgs/vgdino.png" class="teaser img-fluid z-depth-1">
    <abbr class="badge">CVPR</abbr>
  </div>
  <div class="col-sm-9" style="position: relative;width: 100%;padding-right: 15px;padding-left: 20px;">
    <div class="title">Video-GroundingDINO: Towards Open-Vocabulary Spatio-Temporal Video Grounding</div>
    <div class="author"><strong>Syed Talal Wasim</strong>, Muzammal Naseer, Salman Khan, Ming-Hsuan Yang and Fahad Shahbaz Khan</div>
    <div class="periodical"><em>CVPR, 2024</em></div>
    <div class="links">
      <a href="https://arxiv.org/abs/2401.00901" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">PAPER</a>
      <a href="https://talalwasim.github.io" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">CODE</a>
    </div>
  </div>
</div>
</li>

<br>

<li>
<div class="pub-row">
  <div class="col-sm-3 abbr" style="position: relative;padding-right: 15px;padding-left: 15px;">
    <img src="assets/paper_imgs/arvpt.png" class="teaser img-fluid z-depth-1">
    <abbr class="badge">VISAPP</abbr>
  </div>
  <div class="col-sm-9" style="position: relative;width: 100%;padding-right: 15px;padding-left: 20px;">
    <div class="title">AR-VPT: Simple Auto-Regressive Prompts for Adapting Frozen ViTs to Videos</div>
    <div class="author">Muhammad Zain Yousuf, <strong>Syed Talal Wasim</strong>, Syed Nouman Hasany and Muhammad Farhan</div>
    <div class="periodical"><em>VISAPP, 2024</em></div>
    <div class="links">
      <a href="https://doi.org/10.5220/0012392000003660" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">PAPER</a>
      <a href="https://talalwasim.github.io" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">CODE</a>
    </div>
  </div>
</div>
</li>

<br>

<li>
<div class="pub-row">
  <div class="col-sm-3 abbr" style="position: relative;padding-right: 15px;padding-left: 15px;">
    <img src="assets/paper_imgs/text_guided_resilience.png" class="teaser img-fluid z-depth-1">
    <abbr class="badge">NeurIPS</abbr>
  </div>
  <div class="col-sm-9" style="position: relative;width: 100%;padding-right: 15px;padding-left: 20px;">
    <div class="title">Hardware Resilience Properties of Text-Guided Image Classifiers</div>
    <div class="author"><strong>Syed Talal Wasim</strong>, Kabila Haile Soboka, Abdulrahman Mahmoud, Salman Khan, David Brooks and Gu-Yeon Wei</div>
    <div class="periodical"><em>NeurIPS, 2023</em></div>
    <div class="links">
      <a href="https://arxiv.org/abs/2311.14062" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">PAPER</a>
      <a href="https://github.com/TalalWasim/TextGuidedResilience" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">CODE</a>
    </div>
  </div>
</div>
</li>

<br>

<li>
<div class="pub-row">
  <div class="col-sm-3 abbr" style="position: relative;padding-right: 15px;padding-left: 15px;">
    <img src="assets/paper_imgs/video-focalnets.png" class="teaser img-fluid z-depth-1">
    <abbr class="badge">ICCV</abbr>
  </div>
  <div class="col-sm-9" style="position: relative;width: 100%;padding-right: 15px;padding-left: 20px;">
    <div class="title">Video-FocalNets: Spatio-Temporal Focal Modulation for Video Action Recognition</div>
    <div class="author"><strong>Syed Talal Wasim</strong>*, Muhammad Uzair Khattak*, Muzammal Naseer, Salman Khan, Mubarak Shah and Fahad Shahbaz Khan</div>
    <div class="periodical"><em>ICCV, 2023</em></div>
    <div class="links">
      <a href="https://arxiv.org/abs/2307.06947" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">PAPER</a>
      <a href="https://github.com/TalalWasim/Video-FocalNets" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">CODE</a>
    </div>
  </div>
</div>
</li>

<br>

<li>
<div class="pub-row">
  <div class="col-sm-3 abbr" style="position: relative;padding-right: 15px;padding-left: 15px;">
    <img src="assets/paper_imgs/promptsrc.jpg" class="teaser img-fluid z-depth-1">
    <abbr class="badge">ICCV</abbr>
  </div>
  <div class="col-sm-9" style="position: relative;width: 100%;padding-right: 15px;padding-left: 20px;">
    <div class="title">Self-regulating Prompts: Foundational Model Adaptation without Forgetting</div>
    <div class="author">Muhammad Uzair Khattak*, <strong>Syed Talal Wasim</strong>*, Muzammal Naseer, Salman Khan, Ming-Hsuan Yang and Fahad Shahbaz Khan</div>
    <div class="periodical"><em>ICCV, 2023</em></div>
    <div class="links">
      <a href="https://arxiv.org/abs/2307.06948" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">PAPER</a>
      <a href="https://github.com/muzairkhattak/PromptSRC" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">CODE</a>
    </div>
  </div>
</div>
</li>

<br>

<li>
<div class="pub-row">
  <div class="col-sm-3 abbr" style="position: relative;padding-right: 15px;padding-left: 15px;">
    <img src="assets/paper_imgs/vita.png" class="teaser img-fluid z-depth-1">
    <abbr class="badge">CVPR</abbr>
  </div>
  <div class="col-sm-9" style="position: relative;width: 100%;padding-right: 15px;padding-left: 20px;">
    <div class="title">Vita-CLIP: Video and text adaptive CLIP via Multimodal Prompting</div>
    <div class="author"><strong>Syed Talal Wasim</strong>, Muzammal Naseer, Salman Khan, Fahad Shahbaz Khan and Mubarak Shah</div>
    <div class="periodical"><em>CVPR, 2023</em></div>
    <div class="links">
      <a href="https://arxiv.org/abs/2304.03307" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">PAPER</a>
      <a href="https://github.com/TalalWasim/Vita-CLIP" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">CODE</a>
    </div>
  </div>
</div>
</li>

<br>

<li>
<div class="pub-row">
  <div class="col-sm-3 abbr" style="position: relative;padding-right: 15px;padding-left: 15px;">
    <img src="assets/paper_imgs/gest.jpg" class="teaser img-fluid z-depth-1">
    <abbr class="badge">JDMDH</abbr>
  </div>
  <div class="col-sm-9" style="position: relative;width: 100%;padding-right: 15px;padding-left: 20px;">
    <div class="title">Toward Automatic Typography Analysis: Serif Classification and Font Similarities</div>
    <div class="author"><strong>Syed Talal Wasim</strong>, Romain Collaud, Lara DÃ©fayes, Nicolas Henchoz, Mathieu Salzmann and Delphine Ribes</div>
    <div class="periodical"><em>Journal of Data Mining in Digital Humanities (JDMDH), 2023</em></div>
    <div class="links">
      <a href="https://jdmdh.episciences.org/paper/view/id/13008" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">PAPER</a>
      <a href="https://github.com/TalalWasim/GEST-Serif" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">CODE</a>
    </div>
  </div>
</div>
</li>
  
<br>

<li>
<div class="pub-row">
  <div class="col-sm-3 abbr" style="position: relative;padding-right: 15px;padding-left: 15px;">
    <img src="assets/paper_imgs/ecl.jpg" class="teaser img-fluid z-depth-1">
    <abbr class="badge">Frontiers</abbr>
  </div>
  <div class="col-sm-9" style="position: relative;width: 100%;padding-right: 15px;padding-left: 20px;">
    <div class="title">Using Facial Micro-Expressions in Combination With EEG and Physiological Signals for Emotion Recognition</div>
    <div class="author">Nastaran Saffaryazdi, <strong>Syed Talal Wasim</strong>, Kuldeep Dileep, Alireza Farrokhi Nia, Suranga Nanayakkara, Elizabeth Broadbent and Mark Billinghurst</div>
    <div class="periodical"><em>Frontiers in Psychology, 2022</em></div>
    <div class="links">
      <a href="https://www.frontiersin.org/articles/10.3389/fpsyg.2022.864047/full" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">PAPER</a>
    </div>
  </div>
</div>
</li>

<li>
<div class="pub-row">
  <div class="col-sm-3 abbr" style="position: relative;padding-right: 15px;padding-left: 15px;">
    <img src="assets/paper_imgs/cv4animals.png" class="teaser img-fluid z-depth-1">
    <abbr class="badge">CVPRW</abbr>
  </div>
  <div class="col-sm-9" style="position: relative;width: 100%;padding-right: 15px;padding-left: 20px;">
    <div class="title">Sim-to-Real Transfer for Object Detection and Localization on Animals</div>
    <div class="author"><strong>Syed Talal Wasim</strong>, Syed Nouman Hasany, Kainat Abbasi, Huda Feroz, Anisa Aisha Ahmed, Mudasir Hanif Shaikh and Muhammad Farhan</div>
    <div class="periodical"><em>CVPR 2021, CV4Animals Workshop</em></div>
    <div class="links">
      <a href="assets/paper_pdfs/cv4animals.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">POSTER</a>
    </div>
  </div>
</div>
</li>


</ol>
</div>